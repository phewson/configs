##+AUTHOR: Paul Hewson
#+TITLE: WiFi SPARK data notes
#+EMAIL: phewson@wifispark.com
#+TAGS: fundamentals(f)  proprietary(p) splunk(s)

* Splunk mode

ion-android-person-add ion-person-add
ion-android-phone-portrait
ion-android-watch / ion-clock / ion-ios-timer-outline
ion-ios-bolt
ion-ios-cloud-download-outline ion-ios-download-outline
ion-ios-cloud-upload-outline ion-ios-upload-outline


splunk install app http://splunk-base.splunk.com/apps/22348/download/

** Getting data into R
=jsonlite= should parse splunk data

** [[https://orgmode.org/worg/org-contrib/babel/languages.html][babel]] instructions

** minor mode for splunk

* Miscellanous information

** ripgrep for searching with emacs

** Corporate Colors                                             :proprietary:

| name   | hex     | approx X11 name |
|--------+---------+-----------------|
| blue   | #2db8c5 | lightseagreen   |
| yellow | #fdc300 | gold2           |
| green  | #2daa56 | seagreen        |
| grey   | #9d9d9c | gray61          |
| black  | #3c3c3b | gray23          |


** User Journey
 - Captive Network Assistant or webbrowser
 -  TOCs (WiFi SPARK branded)



* Splunk Permissions                                                 :splunk:


** [[https://docs.splunk.com/Documentation/Splunk/8.0.1/Viz/DashboardPermissions][Dashboard share permissions]]
Shared in app -> The dashboard is available to other users in the app context where it was created. For example, if you create the dashboard in the Search and Reporting app, the dashboard is visible to other users in this context. Depending on their permissions, other users can edit the dashboard.
- Use transforming commands in the base search to generate transformed results. Non-transforming base searches can cause performance and timeout issues.


** Mapping in Splunk                                                 :splunk:

Working from [[https://www.splunk.com/en_us/blog/tips-and-tricks/use-custom-polygons-in-your-choropleth-maps.html][Splunk blog]]

1. Choropleth map needs to be imported as .KMZ (a zipped .KML file)
2. Google KML is "just" XML, Splunk needs to know where to find the UIDs.

#+BEGIN_SRC xml
<Placemark>
    <Style><LineStyle><color>ff0000ff</color></LineStyle><PolyStyle><fill>0</fill></PolyStyle></Style>
    <ExtendedData><SchemaData schemaUrl="#OGRGeoJSON">
        <SimpleData name="FID">1</SimpleData>
        <SimpleData name="LAD19CD">E06000001</SimpleData>
#+END_SRC

In this case, the Splunk Spec is */Placemark/ExtendedData/SchemaData/SimpleData[@name='LAD19CD']*

3. Upload the *.kmz* file as a lookup table
4. Create a lookup definition, where the type is set as *Geospatial* and the *Feature Id Element* (requires that Advanced options is ticked up when creating the lookup definition)
5. Slightly hazy about the difference between uploading the lookup and the lookup definition.
6. Modify the dashboard simple xml to include the lines
#+BEGIN_SRC xml
<option name="mapping.tileLayer.url">https://cartodb-basemaps-{s}.global.ssl.fastly.net/dark_all/{z}/{x}/{y}.png</option>
<option name="mapping.showTiles">1</option>
<option name="mapping.tileLayer.attribution">"Map tiles by Carto, under CC BY 3.0. Data by OpenStreetMap, under ODbL."</option>
#+END_SRC
(currently points at the cartodb dark mode map. Other [[https://wiki.openstreetmap.org/wiki/Tile_servers][Tile servers]] are available).
7. The map needs to be linked to a search which tabulates something by a code that matches the codes in the "lookup" polygon

#+BEGIN_SRC splunk
| lookup OAC_by_postcode.csv PCDS AS subscriber.zip_code output LA_CODE as LAD19CD
| stats count by LAD19CD
| geom geo_uk_la_boundaries featureIdField=LAD19CD
#+END_SRC





* Splunk coding

** Command types
 - Streaming commands :: (operates on each event, e.g. bin, autoregress, dedup, eval, join, rename
 - Generating commands :: (generates events or reports from one or more indexes without transforming the events, e.g. search, pivot)
 - Transforming commands (previously Reporting) :: (transform specified cell value, e.g. chart, stats, top, table)
 - Orchestrating commands :: (control aspecs of how seach processed, e.g. lookup when local=true, localop)
 - Dataset processing comamnds :: (need entire data set e.g anomalousvalue, map, outlier, reverse, sort)

** Transactions

- =transaction= seems to be the magic command which links by sessions by the provided UID

#+BEGIN_SRC shell
sourcetype="spark_data" AND ((type="Stop" AND termination_cause != "Suspect-Logout") OR (type = "Start" AND termination_cause != "Resumed"))
| transaction unique_session_id endswith=(type="Stop") startswith=(type="Start") keeporphans=true maxspan=6months
| eval endtime=strftime(_time + duration, "%Y-%m-%d %H:%M:%S")
| eval starttime=strftime(_time, "%Y-%m-%d %H:%M:%S")
| table customer_id, starttime, endtime, duration, eventcount

 | transaction request_id keeporphans=true maxspan=1m
 | where _txn_orphan=1 AND _time<relative_time(now(),"-1month@month")
#+END_SRC

- [[https://answers.splunk.com/answers/492488/how-to-edit-my-search-to-find-orphaned-transaction.html][Orphaned transactions]]

But how can we get data such as:

| customer_id | 23       48          |
| starttime   | 2019-08-22  16:11:57 |
| endtime     | 2019-08-26  04:11:54 |
| duration    | 302397               |
| eventcount  | 2                    |


#+BEGIN_SRC splunk
sourcetype=spark_data AND unique_session_id = "466948025fe874a8a70e89099a0a5295"
| table _time, customer_id, device_mac_address, customer_id, type, termination_cause
| sort customer_id, _time

5e0ef0764d3ab2855873c3f2d5c3a742
466948025fe874a8a70e89099a0a5295
#+END_SRC


* Fundamentals of spark_data

#+BEGIN_SRC
2020-02-06 08:39:36,000 ip-10-0-6-165.eu-west-1.compute.internal INFO     {"type":"Portal","hotspot":{"id":"230","internet_address":"145.255.240.243","symbol":"UNIV011-C","name":"UHNM - Royal Stoke Hospital","mac":"","location":"","latitude":null,"longitude":null,"type":"10","timezone":"UTC","zone_id":"20042","zone_name":"UHNM Royal Stoke"},"interface":{"id":"1037","name":"eth3"},"customer":{"id":"143","name":"University Hospitals of North Midlands","zone_id":"119","zone_name":"University Hospitals of North Midlands","realm":"ph11"},"view":"PortalView_Login_BuyTime","device_mac_address":"D868C384CF05","view_valid":false,"doing_ajax":true,"user_agent":{"browser_name":"Mozilla/5.0 (Linux; Android 9; SM-J330FN Build/PPR1.180610.011; wv) AppleWebKit/537.36 (KHTML, like Gecko) Version/4.0 Chrome/79.0.3945.136 Mobile Safari/537.36","Parent":"Android WebView 4.0","Comment":"Android WebView 4.0","Browser":"Android WebView","Version":"4.0","Platform":"Android","isMobileDevice":true,"Device_Type":"Mobile Phone","isTablet":false,"Language":"en-GB,en-US;q=0.9,en;q=0.8"},"redirect":[],"form_data":[],"username":"","user_id":0,"time_left":0,"timestamp":1580978376,"origin":"http%3A%2F%2Fwww.samsung.com%2F"}
#+END_SRC


** Datrix Hardware
- Datrix are just one example of a hardware provider (e.g. used by NHS). We "piggy back" onto their hardware to provide a public service.

** Data Dictionary
   For [[https://drive.google.com/open?id=1AFeeEqUMDv8vMr2o6qjHf8kDwLRnIjCN&authuser=phewson@wifispark.com&usp=drive_fs][External customers]]

** User agents.
 - Messed up by old code (I think that's fair?)
 - ~sourcetype="spark_data" and type="Portal" | rename user_agent.browser_name as bn | dedup bn | table bn~
 - Could use an [[https://cran.r-project.org/web/packages/uaparserjs/][R package]] to generate a lookup csv as a workaround.

** Ruckus
   [[http://www.ruckuswireless.com/products/smart-wireless-services/spot][Ruckus]] (SPoT - Smart Positioning Technology)


** spark_data  [[https://wifispark.atlassian.net/wiki/spaces/BT/pages/745898649/Splunk-Spark-Data+Dictionary][Splunk-Spark]]                                     :proprietary:

There is
 - spark_data (numerous datasets of type spark_data)
 - spark_cloud ????? (naming of datasets?????)

- Difference between `source_type=spark_data` and `
index=cloud_spark_* AND type = "Portal

*** Two types of event
  - sourcetype="spark_data" view=NewUser (Registration events)

  - sourcetype="spark_data" type=Start OR Stop (contains Session Events)
 total_downloaded_data_gb


*** Session Events (Radius)

 - Radius sends Start event (time, device, etc.).   Idle time out also set.
 - Every (Spark tells Radius interim update interval), usually one hour. Every connected device.
 - Max session length (e.g. 24 hours)
 - Fake start and stop events. We think it's a logout, it's still in RADIUS, but no bandwidth.   FakeStart.

- Radius uses UDP (ping and not care, packages dropped).
- CRON job we will terminate sessions (hourly).
(type="Start" AND termination_cause="Resumed")  Fake Start
(type="Stop" AND termination_cause="Suspect-Logout") Fake Stop



** WiFi
*** Frequency ::  2.4GHz and 5GHz. Note Microwave uses 2.450GHz
    - IEEE 802.11 :: standard sets out the following standards for Wi-Fi types
      - 802.11a :: uses 5GHz frequencies of 5 GHz (up to 54 megabits a second). Usess OFDM (orthogonal frequency division multiplexing)
      - 802.11b :: uses 2.4 GHz (up to 11 megabits a second). Range of 46 meters, largely redundant nowadays. Complementary coded keying (CCK)- using quadrature phase shift keying.
      - 802.11g :: uses 2.4 GHz (up to 54 megabits a second). Uses same OFDM as 802.11b and is backward compatible with older standards.
      - 802.11n :: uses 5GHz (up to 140 megabits, and theoretically supports up to 450 Mbps). Introduced in 2009, aka Wi-Fi 4. Uses MIMO (Multiple Input Multiple Output) where multiple transmitters/receivers operate simultaneously at one or both ends of the link.
      - 802.11ac :: uses 5GHz (aka Wi-Fi 5) (between 433 Mbps and 1 gigabit per second). Supports up to eight spatial streams, uses MIMO
      - 802.11ax ::  (aka Wi-Fi 6)
*** 802.11 frames
  - [[https://en.wikipedia.org/wiki/802.11_Frame_Types][802.11 Frames]]
*** OSI model
  - [[https://en.wikipedia.org/wiki/OSI_model][OSI model]]
*** Modes
  - Infrastructure
  - Ad hoc (c.f. back to back network)
*** Medium Access Control
  - [[https://en.wikipedia.org/wiki/Medium_access_control][MAC]]
  -  (CSMA/CA) :: Carrier Sense Multiple Access with Collision Avoidance media access control protocol
  - WiFi systems are the half duplex shared media configurations, where all stations transmit and receive on the same radio channel, so the station cannot hear while it is sending and cannot detect a colisions.
  - [[https://en.wikipedia.org/wiki/Distributed_coordination_function][Distributed Coordination Function]].  WiFi station transmits only when channel is clear, without acknowledgement will assume a collision and retry.
  - Quality of service capabilities enahnced in 802.11e by:
    - WiFi Multimedia Extensions (WME) − Mandatory
    - WiFi Scheduled Multimedia (WSM) − Optional
  - [[https://en.wikipedia.org/wiki/Point_coordination_function][Point coordination function]] - not implemented
  - [[https://www.wi-fi.org/][WiFi alliance]]
  - [[http://www.wimaxforum.org/home/][WiMAX forum]]

** WiFi roaming (client asks to use an AP)
   e.g.  [[https://hometoys.com/demystifying-wi-fi-roaming/][WiFi roaming]]

** RADIUS                                                      :fundamentals:

1) On port 1812, centralized AAA/Triple A ([[https://tools.ietf.org/html/rfc2865][Authentication, Authorization]], [[https://tools.ietf.org/html/rfc2866][Accounting]]).
2) Dates to 1991
3) Runs in Application Layer
4) A [[https://jumpcloud.com/blog/radius-improve-wifi-security/][security application]] (users authenticate with their own credentials, rather than a WiFi password written on whiteboard or bit of paper.
5) [[https://tools.ietf.org/html/rfc4282][Realms]] are somewhat arbitrary domain like (e.g. paul@thisfreewifi) - exist to help with roaming
6) Radius codes (decimal)

| Code | Assignment                   |
|------+------------------------------|
|    1 | Access-Request               |
|    2 | Access-Accept                |
|    3 | Access-Reject                |
|    4 | Accounting-Request           |
|    5 | Accounting-Response          |
|   11 | Access-Challenge             |
|   12 | Status-Server (experimental) |
|   13 | Status-Client (experimental) |
|   40 | Disconnect-Request           |
|   41 | Disconnect-ACK               |
|   42 | Disconnect-NAK               |
|   43 | CoA-Request                  |
|   44 | CoA-ACK                      |
|   45 | CoA-NAK                      |
|  255 | Reserved                     |

#+BEGIN_SRC dot :file radius.png :cmdline -Kdot -Tpng
digraph G {
    graph [fontname = "Calibri:style=Regular"];
    node [fontname = "Calibri:style=Regular"];
    edge [fontname = "Calibri:style=Regular"];
    label="Radius Packet";
    color="purple";
    host [shape=record, label="{{0 Code | 8 Packet Identifier | 16 Length 32} | Authenticator | AVPs...}"];
    }
#+END_SRC

#+RESULTS:
[[file:radius.png]]



** UDP: User (Unreliable)  Datagram Protocol                   :fundamentals:

- Simple message-oriented transport layer protocol [[https://tools.ietf.org/html/rfc768][RFC 768]]
- No retransmission of dropped packages
- Used for DNS, NTP, DHCP, streaming media

*UDP header*

| Offsets | Octet | 0       | 1        | 2           | 3         |
|---------+-------+---------+----------+-------------+-----------|
|   Octet |   Bit | 0 ... 7 | 8 ... 15 | 16 ... 23   | 24 ... 31 |
|       0 |     0 | Source  | port     | Destination | Port      |
|       4 |    32 | Length  | (h+data) | Check       | sum       |

Checksum optional in IPv4, mandatory in IPv6.   IPv$ limited to 65,535 bytes.


*IPv4 pseudo header*

| Offsets | Octet | 0           | 1        | 2           | 3         |
|---------+-------+-------------+----------+-------------+-----------|
|   Octet |   Bit | 0 ... 7     | 8 ... 15 | 16 ... 23   | 24 ... 31 |
|       0 |     0 | Source      | IP       | Address     |           |
|       4 |    32 | Destination | IP       | Address     |           |
|       8 |    64 | Zeroes      | Protocol | UDP         | Length    |
|      12 |    96 | Source      | port     | Destination | Port      |
|      16 |   128 | Length      | (h+data) | Check       | sum       |
|      20 |  160+ | Data        |          |             |           |


#+BEGIN_SRC ditaa :file data-feed.png

+------------+
|            |
|  Radius    +------------+
|            |            |             +----------+   +-------+   +-------------+
+-------+----+            |             | Spark    |   |  .dat |   | Splunk      |
        |                 +---Redis---->+ Analytics+-->+       +-->+ Universal   |
        v                 |             | Daemon   |   |  file |   | Forwarder   |
+-------+------+          |             +----------+   +-------+   +-------------+
|              |          |
| Spark        +----------+
|  (sparkDB)   |
+-------+------+
        |
        v
+-------+--------+
|                |
|    Flint       |
|                |
+----------------+

#+END_SRC

#+RESULTS:
[[file:data-feed.png]]


#+BEGIN_SRC ditaa :file c:/Users/phewson/analytics.png

+--------------+            +------------------------+
| Splunk       +----------->+ (splunk                |     +---------------+
| Universal    |            |  Indexer 1)   Splunk   |     | Output        |
| Forwarder    +----------->+ (splunk       Search   +---->+ e.g. Customer |
+--------------+            | Indexer 2)    Head     |     | Dashboards    |
                            + -----------------------+     +---------------+

#+END_SRC


#+END_SRC
#+BEGIN_SRC ditaa :file c:/Users/phewson/authentication.png

       +-----------------------------------------------+
       |                                               |
       v                   +------------------+        |
+------+--------+          | Web Admin        |        |
| (sparkDB)     +          | Client admin user|        |    +--------+--------+
+------+--------+          | *analytics role  |        |    | CWA Admin       |
       ^                   | *OAuth creds     |        |    +--------+--------+
       |                   +--+---------------+        |             |
       |                      |                        |             |
       +----------------------+                        |             |
       |                                               |             v
       v                                            +--+-------------+--+
+------+-------+                                    | CWA Analytics     |
| Splunk       |                                    +--+----------------+
| Search       |                                       |
| Head         +<--------------------------------------+
+--------------+

#+END_SRC


sourcetype=spark_data "PortalView" | fields hotspot.internet_address | stats count by hotspot.internet_address
sourcetype=spark_data "PortalView" | fields subscriber.zip_code | stats count by subscriber.zip_code

sourcetype=spark_data (view="PortalView") |  fields subscriber.zip_code | lookup ukpostcodes.csv postcode AS subscriber.zip_code | geostats count by subscriber.zip_code latfield=latitude longfield=longitude

sourcetype=spark_data (view="PortalView") |  fields subscriber.zip_code | lookup OAC_by_postcode.csv PCDS AS subscriber.zip_code | stats count by SUBGRP

sourcetype=spark_data (view="PortalView") |  fields subscriber.zip_code | lookup OAC_by_postcode.csv PCDS AS subscriber.zip_code output SUBGRP | lookup OAC_2011_description.csv SUBGRP output SUBGRP, supergroup, description | lookup interim_OAC_2011_names.csv SUBGRP | stats count by group_labels, description, f1, f2, f3 | sort count desc


sourcetype=spark_data (view="PortalView") |  fields subscriber.zip_code | lookup OAC_by_postcode.csv PCDS AS subscriber.zip_code output SUBGRP | lookup OAC_2011_description.csv SUBGRP |  lookup interim_OAC_2011_names.csv SUBGRP | stats count by subgroup_label, description, f1, f2, f3, f4  | sort count desc



* Regexp

 - Emacs replace tab is literally press the tab key and return
 - Emacs *replace-regexp* ^.\{6\} with \&,



* Dataflowchart

sourcetype=spark_data

af_ versus cf_

realm
login_type=[data_click, email_val, free_sub, free_subscriber]
reason=[expired, user_reset]
user_agent

annual_total_upload_data_gb	annual_total_download_data_gb

#+BEGIN_SRC dot :file data_f.png :cmdline -Kdot -Tpng
digraph G {
    compound=true;
    subgraph cluster0 {
    graph [fontname = "Calibri:style=Regular"];
    node [fontname = "Calibri:style=Regular"];
    edge [fontname = "Calibri:style=Regular"];
    label="Data Sources";
    color="purple";
    host [shape=record, label="{host:|{cloud |testing_core| testing_portal}|sourcetype='spark_data'}"];
    }

    subgraph cluster1 {
    graph [fontname = "Calibri:style=Regular"];
    node [fontname = "Calibri:style=Regular"];
    edge [fontname = "Calibri:style=Regular"];
    label="Event Data"
    key [shape=record, label="UID: | unique_session_id"];
    type [shape=record, label="{type:|{<f1>Portal (Registration) |<f2> Stop/Start (Session)}}"];
    start [shape=record, label="{Start|{termination_clause:}|{null | Resumed}}", color=blue];
    edge [color="red"];
    type:f1 -> portal;
    edge [color="blue"];
    type:f2 -> stop;
    edge [color="blue"];
    type:f2 -> start;
    portal [shape=record,
            label="{view|{PortalView_Login_FreeSub | PortalView_NotHotspot | PortalView_Process_FreeSub}|
            {<p1>EmailValidation | <p2>NewUser | <p3>PortalView | <p4>PortalView_Login | <p5>ResetUser}}", color=red];
    stop [shape=record, label="{Stop|{termination_clause:}|
          {<t0>User-Request | <t1>Suspect-Logout | <t2>Resumed | <t3>Session-Timeout | <t4>Idle-Timeout |
           <t5>Idle-Timeout-Cron}}",
          color="red"];
    stop:t0 -> usage;
    stop:t2 -> usage;
    stop:t3 -> usage;
    stop:t4 -> usage;
    stop:t5 -> usage;
    usage [shape=record, label="input octets/gigawords  | output octets/gigawords",
           color="blue"];
    spage [shape=record, label="{page|{account_login | manage_account |a ccount_registration |welcome_back}|
           {validation_required | wifi_registration | account_success | form_data}}",color=red];
    edge [color="red"];
    portal:p3 -> spage;
    customer_info [shape=record, label="{customer|{id | name | zone_id | zone_name}}"];
    hotspot [shape=record, label="{hotspot | {latitude | longitude | location | id  | internet_address} |
             {type | zone_id | zone_name | mac | symbol | name | timezone}}"];
    hotspot_id [shape=record, label="hotspot_id"];
    customer_id [shape=record, label="customer_id"];
    }
    host -> type [ltail=cluster0,lhead=cluster1];
    usage -> customer_id;
    customer_id -> hotspot_id;
    start -> customer_id;
    spage -> customer_info;
    customer_info -> hotspot;

}
#+END_SRC

#+RESULTS:
[[file:data_f.png]]


#+BEGIN_SRC dot :file api_ex.png :cmdline -Kdot -Tpng
digraph G {

  subgraph cluster_source_data {
    graph [fontname = "Calibri:style=Regular"];
    node [fontname = "Calibri:style=Regular"];
    label="";
    style="filled";
    color="lightseagreen";
    fillcolor="lightseagreen";
    source_data [shape=record, fillcolor="gold2", style="filled", label="{Exported from Splunk|{(For development purposes)}|{Sessions | Registrations}}"];
    data_transformation [shape=record, fillcolor="gold2", style="filled", label="{Data Transformation |{Aggregate (e.g. montly total) | Compute (e.g. occupancy) | Supplement (e.g. OAC)}}"];
    api [shape=record, fillcolor="gold2", style="filled", label="{API|{Serve processed data} | {Query by} | {customer_id|hotspot|dates}}"];
  };

  subgraph cluster_dashboard {
    graph [fontname = "Calibri:style=Regular"];
    node [fontname = "Calibri:style=Regular"];
    label="";
    style="filled";
    color="seagreen";
    fillcolor="seagreen";
    dashboard [shape=record, fillcolor="gold2", style="filled", label="{Call API | flexdashboard | Render data}"];
  };

  subgraph cluster_testing {
    graph [fontname = "Calibri:style=Regular"];
    node [fontname = "Calibri:style=Regular"];
    label="";
    style="filled";
    color="seagreen";
    fillcolor="seagreen";
    swagger [shape=record, fillcolor="gold2", style="filled", label="{Call API | Test with Swagger}"];
  };


  source_data -> data_transformation;
  data_transformation -> api;
  api -> swagger;
  api -> dashboard;
}
#+END_SRC

#+RESULTS:
[[file:api_ex.png]]




#+BEGIN_SRC dot :file splunk_dev_infra.png :cmdline -Kdot -Tpng
digraph G {

  subgraph cluster_location {
    graph [fontname = "Calibri:style=Regular"];
    node [fontname = "Calibri:style=Regular"];
    label="";
    style="filled";
    color="gray61";
    fillcolor="gray61";
    location [shape=record, fillcolor="gold2", style="filled", label="{Location Data|{Ruckus|Meraki}}"];
  };

  subgraph cluster_portals {
    graph [fontname = "Calibri:style=Regular"];
    node [fontname = "Calibri:style=Regular"];
    label="";
    style="filled";
    color="gray61";
    fillcolor="gray61";
    portals [shape=record, fillcolor="gold2", style="filled", label="{{Redirect Portals|Portal Generator}}"];
  };

  subgraph cluster_redis {
    graph [fontname = "Calibri:style=Regular"];
    node [fontname = "Calibri:style=Regular"];
    label="";
    style="filled";
    color="gray61";
    fillcolor="gray61";
    redis [shape=record, fillcolor="gold2", style="filled", label="{{<F0>API|<F1>Radius}|{<F2>Redis}}"];
  };

  subgraph cluster_dat {
    graph [fontname = "Calibri:style=Regular"];
    node [fontname = "Calibri:style=Regular"];
    label="";
    style="filled";
    color="gray61";
    fillcolor="gray61";
    dat_file [shape=record, fillcolor="gold2", style="filled", label="{Data daemon|{spark-phase11/src/master/spark-analytics-data/}|{Outputs .dat file}|{\<text date, ip, server\> INFO \{json\}}}"];
  };

  subgraph cluster_forwarder {
    graph [fontname = "Calibri:style=Regular"];
    node [fontname = "Calibri:style=Regular"];
    label = "";
    style="filled";
    color="gray61";
    fillcolor="gray61";
    forwarder [shape=record, fillcolor="gold2", style="filled", label="{Forwarder|{/opt/splunkforwarder/etc/apps/search/local/inputs.conf}}"];
  };

  subgraph cluster_conf {
    graph [fontname = "Calibri:style=Regular"];
    node [fontname = "Calibri:style=Regular"];
    label="";
    style="filled";
    color="lightseagreen";
    fillcolor="lightseagreen";
    cluster_confs [shape=record, fillcolor="gold2", style="filled", label="{Unknown (app)|{/opt/splunk/etc/apps/\<app\>/local/transforms.conf}|{/opt/splunk/etc/apps/\<app\>/local/props.conf}}"];
  };

  subgraph cluster_0indexer1 {
    graph [fontname = "Calibri:style=Regular"];
    node [fontname = "Calibri:style=Regular"];
    label="Split index by customer id";
    style="filled";
    color="lightseagreen";
    fillcolor="lightseagreen";
    indexer1 [shape=record, fillcolor="gold2", style="filled", label="{<F1> indexer|{<F2> wfs-development-splunk-indexer1}|{c4.large | 34.254.115.197}}"];
  };

  subgraph cluster_1indexer2 {
    graph [fontname = "Calibri:style=Regular"];
    node [fontname = "Calibri:style=Regular"];
    label="Split index by customer id";
    style="filled";
    color="lightseagreen";
    fillcolor="lightseagreen";
    indexer2 [shape=record, fillcolor="gold2", style="filled", label="{<F1> indexer |{<F2> wfs-development-splunk-indexer2}|{c4.large | 52.210.107.135}}"];
  };

  subgraph cluster_2search {
    graph [fontname = "Calibri:style=Regular"];
    node [fontname = "Calibri:style=Regular"];
    label="";
    style="filled";
    color="seagreen";
    fillcolor="seagreen";
    search [shape=record, fillcolor="gold2", style="filled", label="{<F1> search head |{<F2> wfs-development-splunk-search}|{c4.large | 52.48.117.173}}"];
  };

  subgraph cluster_search_conf {
    graph [fontname = "Calibri:style=Regular"];
    node [fontname = "Calibri:style=Regular"];
    label="";
    style="filled";
    color="seagreen";
    fillcolor="seagreen";
    search_confs [shape=record, fillcolor="gold2", style="filled", label="{All_Field_Aliases (app) |{/opt/splunk/etc/apps/all_field_aliases/local/transforms.conf} |{/opt/splunk/etc/apps/all_field_aliases/local/props.conf}}"];
  };


  indexer1 -> search [penwidth=3.0];
  indexer2 -> search [penwidth=3.0];
  dat_file -> forwarder [penwidth=3.0];
  forwarder -> indexer1 [penwidth=3.0];
  forwarder -> indexer2 [penwidth=3.0];
  search_confs -> search:F2 [arrowhead="dot"];
  cluster_confs -> indexer1:F2 [arrowhead="dot"];
  cluster_confs -> indexer2:F2 [arrowhead="dot"];
  portals -> redis:F1 [penwidth=3.0];
  redis:F2 -> dat_file [penwidth=3.0];

}
#+END_SRC

#+RESULTS:
[[file:api_ex.png]]

#+BEGIN_SRC dot :file splunk_dev.png :cmdline -Kdot -Tpng
digraph G {
  bgcolor="gray61";
  /* admin;
  poweruser;
  user;
  admin -> poweruser -> user; */

  subgraph cluster_source {
    graph [fontname = "Calibri:style=Regular"];
    node [fontname = "Calibri:style=Regular"];
    label="";
    style="filled";
    color="lightseagreen:seagreen";
    fillcolor="lightseagreen:seagreen";
    gradientangle=270;
    source_spark [shape=record, fillcolor="gold2", style="filled", label="{source|{/usr/local/spark/logs/spark-analytics-filter.dat}}"];
    source_location [shape=record, fillcolor="gold2", style="filled", label="{source|{/usr/share/location-data-collection/output/cloud_spark_location_NUMBER.dat}}"];
}
  subgraph cluster_host {
    graph [fontname = "Calibri:style=Regular"];
    node [fontname = "Calibri:style=Regular"];
    label="";
    style="filled";
    color="lightseagreen";
    fillcolor="lightseagreen";
    host_location [shape=record, fillcolor="gold2", style="filled", label="{host|{ip-10-0-1-73 | location-test.wifispark.net}}"];
    host_spark [shape=record, fillcolor="gold2", style="filled", label="{host|{cloud | testing_core | testing_portal}}"];
}
  subgraph cluster_data {
    graph [fontname = "Calibri:style=Regular"];
    node [fontname = "Calibri:style=Regular"];
    label="";
    style="filled";
    color="seagreen";
    fillcolor="seagreen";
    source_types [shape=record, fillcolor="gold2", style="filled",
                  label="{source_types|{<ST1>spark_data}|{<ST2>location_data}|{egton_radius_data}|{westpoint_location_data}}"];
    indexes [shape=record, fillcolor="gold2", style="filled",
             label="{indexes|{<I1>cloud_spark_NUMBER}|{<I2>hotsplot_NUMBER}|{<I3>spark_analytics_data_monitoring}|{spark_data_feed_failures}|{spark_data_feed_monitoring}|{BESPOKE_CUSTOMERS}|{BESPOKE_TESTS/DEMOS}}"];
}
  source_spark -> source_types:ST1 [color="red"];
  source_location -> source_types:ST2;
  source_spark -> indexes:I1;
  source_location -> indexes:I2;
  host_spark -> source_spark;
  host_location -> source_location;
  indexes:I1 -> source_types:ST1;
  {rank=same indexes source_types}


}
#+END_SRC

#+RESULTS:
[[file:splunk_dev.png]]


Splunk assigns host values as follows:

1. Any event-specific host assignment that you specify in transforms.conf.
2. The default host value for the input that created the event, if any (the forwarder or indexer which first consumes the data)
3. The default host value for the Splunk indexer or forwarder that initially consumes the data.

Splunk indexes

We have one index per customer. The data for these are stored in distinct folders. This seems to be the place to control access.

Why do we need to restrict permissions by host, why not by index?
Why not use tagging cloud=blah blah blah
Tags could be different in prod/dev. They would be the only thing that different.

wmi-override-host
=======
##+AUTHOR: Paul Hewson
#+TITLE: WiFi SPARK data notes
#+EMAIL: phewson@wifispark.com
#+TAGS: fundamentals(f)  proprietary(p) splunk(s)

* Splunk mode

ion-android-person-add ion-person-add
ion-android-phone-portrait
ion-android-watch / ion-clock / ion-ios-timer-outline
ion-ios-bolt
ion-ios-cloud-download-outline ion-ios-download-outline
ion-ios-cloud-upload-outline ion-ios-upload-outline


splunk install app http://splunk-base.splunk.com/apps/22348/download/

** Getting data into R
=jsonlite= should parse splunk data

** [[https://orgmode.org/worg/org-contrib/babel/languages.html][babel]] instructions

** minor mode for splunk

* Miscellanous information

** ripgrep for searching with emacs

** Corporate Colors                                             :proprietary:

| name   | hex     | approx X11 name |
|--------+---------+-----------------|
| blue   | #2db8c5 | lightseagreen   |
| yellow | #fdc300 | gold2           |
| green  | #2daa56 | seagreen        |
| grey   | #9d9d9c | gray61          |
| black  | #3c3c3b | gray23          |


** User Journey
 - Captive Network Assistant or webbrowser
 -  TOCs (WiFi SPARK branded)



* Splunk Permissions                                                 :splunk:


** [[https://docs.splunk.com/Documentation/Splunk/8.0.1/Viz/DashboardPermissions][Dashboard share permissions]]
Shared in app -> The dashboard is available to other users in the app context where it was created. For example, if you create the dashboard in the Search and Reporting app, the dashboard is visible to other users in this context. Depending on their permissions, other users can edit the dashboard.
- Use transforming commands in the base search to generate transformed results. Non-transforming base searches can cause performance and timeout issues.


** Mapping in Splunk                                                 :splunk:

Working from [[https://www.splunk.com/en_us/blog/tips-and-tricks/use-custom-polygons-in-your-choropleth-maps.html][Splunk blog]]

1. Choropleth map needs to be imported as .KMZ (a zipped .KML file)
2. Google KML is "just" XML, Splunk needs to know where to find the UIDs.

#+BEGIN_SRC xml
<Placemark>
    <Style><LineStyle><color>ff0000ff</color></LineStyle><PolyStyle><fill>0</fill></PolyStyle></Style>
    <ExtendedData><SchemaData schemaUrl="#OGRGeoJSON">
        <SimpleData name="FID">1</SimpleData>
        <SimpleData name="LAD19CD">E06000001</SimpleData>
#+END_SRC

In this case, the Splunk Spec is */Placemark/ExtendedData/SchemaData/SimpleData[@name='LAD19CD']*

3. Upload the *.kmz* file as a lookup table
4. Create a lookup definition, where the type is set as *Geospatial* and the *Feature Id Element* (requires that Advanced options is ticked up when creating the lookup definition)
5. Slightly hazy about the difference between uploading the lookup and the lookup definition.
6. Modify the dashboard simple xml to include the lines
#+BEGIN_SRC xml
<option name="mapping.tileLayer.url">https://cartodb-basemaps-{s}.global.ssl.fastly.net/dark_all/{z}/{x}/{y}.png</option>
<option name="mapping.showTiles">1</option>
<option name="mapping.tileLayer.attribution">"Map tiles by Carto, under CC BY 3.0. Data by OpenStreetMap, under ODbL."</option>
#+END_SRC
(currently points at the cartodb dark mode map. Other [[https://wiki.openstreetmap.org/wiki/Tile_servers][Tile servers]] are available).
7. The map needs to be linked to a search which tabulates something by a code that matches the codes in the "lookup" polygon

#+BEGIN_SRC splunk
| lookup OAC_by_postcode.csv PCDS AS subscriber.zip_code output LA_CODE as LAD19CD
| stats count by LAD19CD
| geom geo_uk_la_boundaries featureIdField=LAD19CD
#+END_SRC





* Splunk coding

** Command types
 - Streaming commands :: (operates on each event, e.g. bin, autoregress, dedup, eval, join, rename
 - Generating commands :: (generates events or reports from one or more indexes without transforming the events, e.g. search, pivot)
 - Transforming commands (previously Reporting) :: (transform specified cell value, e.g. chart, stats, top, table)
 - Orchestrating commands :: (control aspecs of how seach processed, e.g. lookup when local=true, localop)
 - Dataset processing comamnds :: (need entire data set e.g anomalousvalue, map, outlier, reverse, sort)

** Transactions

- =transaction= seems to be the magic command which links by sessions by the provided UID

#+BEGIN_SRC shell
sourcetype="spark_data" AND ((type="Stop" AND termination_cause != "Suspect-Logout") OR (type = "Start" AND termination_cause != "Resumed"))
| transaction unique_session_id endswith=(type="Stop") startswith=(type="Start") keeporphans=true maxspan=6months
| eval endtime=strftime(_time + duration, "%Y-%m-%d %H:%M:%S")
| eval starttime=strftime(_time, "%Y-%m-%d %H:%M:%S")
| table customer_id, starttime, endtime, duration, eventcount

 | transaction request_id keeporphans=true maxspan=1m
 | where _txn_orphan=1 AND _time<relative_time(now(),"-1month@month")
#+END_SRC

- [[https://answers.splunk.com/answers/492488/how-to-edit-my-search-to-find-orphaned-transaction.html][Orphaned transactions]]

But how can we get data such as:

| customer_id | 23       48          |
| starttime   | 2019-08-22  16:11:57 |
| endtime     | 2019-08-26  04:11:54 |
| duration    | 302397               |
| eventcount  | 2                    |


#+BEGIN_SRC splunk
sourcetype=spark_data AND unique_session_id = "466948025fe874a8a70e89099a0a5295"
| table _time, customer_id, device_mac_address, customer_id, type, termination_cause
| sort customer_id, _time

5e0ef0764d3ab2855873c3f2d5c3a742
466948025fe874a8a70e89099a0a5295
#+END_SRC


* Fundamentals of spark_data

#+BEGIN_SRC
2020-02-06 08:39:36,000 ip-10-0-6-165.eu-west-1.compute.internal INFO     {"type":"Portal","hotspot":{"id":"230","internet_address":"145.255.240.243","symbol":"UNIV011-C","name":"UHNM - Royal Stoke Hospital","mac":"","location":"","latitude":null,"longitude":null,"type":"10","timezone":"UTC","zone_id":"20042","zone_name":"UHNM Royal Stoke"},"interface":{"id":"1037","name":"eth3"},"customer":{"id":"143","name":"University Hospitals of North Midlands","zone_id":"119","zone_name":"University Hospitals of North Midlands","realm":"ph11"},"view":"PortalView_Login_BuyTime","device_mac_address":"D868C384CF05","view_valid":false,"doing_ajax":true,"user_agent":{"browser_name":"Mozilla/5.0 (Linux; Android 9; SM-J330FN Build/PPR1.180610.011; wv) AppleWebKit/537.36 (KHTML, like Gecko) Version/4.0 Chrome/79.0.3945.136 Mobile Safari/537.36","Parent":"Android WebView 4.0","Comment":"Android WebView 4.0","Browser":"Android WebView","Version":"4.0","Platform":"Android","isMobileDevice":true,"Device_Type":"Mobile Phone","isTablet":false,"Language":"en-GB,en-US;q=0.9,en;q=0.8"},"redirect":[],"form_data":[],"username":"","user_id":0,"time_left":0,"timestamp":1580978376,"origin":"http%3A%2F%2Fwww.samsung.com%2F"}
#+END_SRC


** Datrix Hardware
- Datrix are just one example of a hardware provider (e.g. used by NHS). We "piggy back" onto their hardware to provide a public service.

** Data Dictionary
   For [[https://drive.google.com/open?id=1AFeeEqUMDv8vMr2o6qjHf8kDwLRnIjCN&authuser=phewson@wifispark.com&usp=drive_fs][External customers]]

** User agents.
 - Messed up by old code (I think that's fair?)
 - ~sourcetype="spark_data" and type="Portal" | rename user_agent.browser_name as bn | dedup bn | table bn~
 - Could use an [[https://cran.r-project.org/web/packages/uaparserjs/][R package]] to generate a lookup csv as a workaround.

** Ruckus
   [[http://www.ruckuswireless.com/products/smart-wireless-services/spot][Ruckus]] (SPoT - Smart Positioning Technology)


** spark_data  [[https://wifispark.atlassian.net/wiki/spaces/BT/pages/745898649/Splunk-Spark-Data+Dictionary][Splunk-Spark]]                                     :proprietary:

There is
 - spark_data (numerous datasets of type spark_data)
 - spark_cloud ????? (naming of datasets?????)

- Difference between `source_type=spark_data` and `
index=cloud_spark_* AND type = "Portal

*** Two types of event
  - sourcetype="spark_data" view=NewUser (Registration events)

  - sourcetype="spark_data" type=Start OR Stop (contains Session Events)
 total_downloaded_data_gb


*** Session Events (Radius)

 - Radius sends Start event (time, device, etc.).   Idle time out also set.
 - Every (Spark tells Radius interim update interval), usually one hour. Every connected device.
 - Max session length (e.g. 24 hours)
 - Fake start and stop events. We think it's a logout, it's still in RADIUS, but no bandwidth.   FakeStart.

- Radius uses UDP (ping and not care, packages dropped).
- CRON job we will terminate sessions (hourly).
(type="Start" AND termination_cause="Resumed")  Fake Start
(type="Stop" AND termination_cause="Suspect-Logout") Fake Stop



** WiFi
*** Frequency ::  2.4GHz and 5GHz. Note Microwave uses 2.450GHz
    - IEEE 802.11 :: standard sets out the following standards for Wi-Fi types
      - 802.11a :: uses 5GHz frequencies of 5 GHz (up to 54 megabits a second). Usess OFDM (orthogonal frequency division multiplexing)
      - 802.11b :: uses 2.4 GHz (up to 11 megabits a second). Range of 46 meters, largely redundant nowadays. Complementary coded keying (CCK)- using quadrature phase shift keying.
      - 802.11g :: uses 2.4 GHz (up to 54 megabits a second). Uses same OFDM as 802.11b and is backward compatible with older standards.
      - 802.11n :: uses 5GHz (up to 140 megabits, and theoretically supports up to 450 Mbps). Introduced in 2009, aka Wi-Fi 4. Uses MIMO (Multiple Input Multiple Output) where multiple transmitters/receivers operate simultaneously at one or both ends of the link.
      - 802.11ac :: uses 5GHz (aka Wi-Fi 5) (between 433 Mbps and 1 gigabit per second). Supports up to eight spatial streams, uses MIMO
      - 802.11ax ::  (aka Wi-Fi 6)
*** 802.11 frames
  - [[https://en.wikipedia.org/wiki/802.11_Frame_Types][802.11 Frames]]
*** OSI model
  - [[https://en.wikipedia.org/wiki/OSI_model][OSI model]]
*** Modes
  - Infrastructure
  - Ad hoc (c.f. back to back network)
*** Medium Access Control
  - [[https://en.wikipedia.org/wiki/Medium_access_control][MAC]]
  -  (CSMA/CA) :: Carrier Sense Multiple Access with Collision Avoidance media access control protocol
  - WiFi systems are the half duplex shared media configurations, where all stations transmit and receive on the same radio channel, so the station cannot hear while it is sending and cannot detect a colisions.
  - [[https://en.wikipedia.org/wiki/Distributed_coordination_function][Distributed Coordination Function]].  WiFi station transmits only when channel is clear, without acknowledgement will assume a collision and retry.
  - Quality of service capabilities enahnced in 802.11e by:
    - WiFi Multimedia Extensions (WME) − Mandatory
    - WiFi Scheduled Multimedia (WSM) − Optional
  - [[https://en.wikipedia.org/wiki/Point_coordination_function][Point coordination function]] - not implemented
  - [[https://www.wi-fi.org/][WiFi alliance]]
  - [[http://www.wimaxforum.org/home/][WiMAX forum]]

** WiFi roaming (client asks to use an AP)
   e.g.  [[https://hometoys.com/demystifying-wi-fi-roaming/][WiFi roaming]]

** RADIUS                                                      :fundamentals:

1) On port 1812, centralized AAA/Triple A ([[https://tools.ietf.org/html/rfc2865][Authentication, Authorization]], [[https://tools.ietf.org/html/rfc2866][Accounting]]).
2) Dates to 1991
3) Runs in Application Layer
4) A [[https://jumpcloud.com/blog/radius-improve-wifi-security/][security application]] (users authenticate with their own credentials, rather than a WiFi password written on whiteboard or bit of paper.
5) [[https://tools.ietf.org/html/rfc4282][Realms]] are somewhat arbitrary domain like (e.g. paul@thisfreewifi) - exist to help with roaming
6) Radius codes (decimal)

| Code | Assignment                   |
|------+------------------------------|
|    1 | Access-Request               |
|    2 | Access-Accept                |
|    3 | Access-Reject                |
|    4 | Accounting-Request           |
|    5 | Accounting-Response          |
|   11 | Access-Challenge             |
|   12 | Status-Server (experimental) |
|   13 | Status-Client (experimental) |
|   40 | Disconnect-Request           |
|   41 | Disconnect-ACK               |
|   42 | Disconnect-NAK               |
|   43 | CoA-Request                  |
|   44 | CoA-ACK                      |
|   45 | CoA-NAK                      |
|  255 | Reserved                     |

#+BEGIN_SRC dot :file radius.png :cmdline -Kdot -Tpng
digraph G {
    graph [fontname = "Calibri:style=Regular"];
    node [fontname = "Calibri:style=Regular"];
    edge [fontname = "Calibri:style=Regular"];
    label="Radius Packet";
    color="purple";
    host [shape=record, label="{{0 Code | 8 Packet Identifier | 16 Length 32} | Authenticator | AVPs...}"];
    }
#+END_SRC

#+RESULTS:
[[file:radius.png]]



** UDP: User (Unreliable)  Datagram Protocol                   :fundamentals:

- Simple message-oriented transport layer protocol [[https://tools.ietf.org/html/rfc768][RFC 768]]
- No retransmission of dropped packages
- Used for DNS, NTP, DHCP, streaming media

*UDP header*

| Offsets | Octet | 0       | 1        | 2           | 3         |
|---------+-------+---------+----------+-------------+-----------|
|   Octet |   Bit | 0 ... 7 | 8 ... 15 | 16 ... 23   | 24 ... 31 |
|       0 |     0 | Source  | port     | Destination | Port      |
|       4 |    32 | Length  | (h+data) | Check       | sum       |

Checksum optional in IPv4, mandatory in IPv6.   IPv$ limited to 65,535 bytes.


*IPv4 pseudo header*

| Offsets | Octet | 0           | 1        | 2           | 3         |
|---------+-------+-------------+----------+-------------+-----------|
|   Octet |   Bit | 0 ... 7     | 8 ... 15 | 16 ... 23   | 24 ... 31 |
|       0 |     0 | Source      | IP       | Address     |           |
|       4 |    32 | Destination | IP       | Address     |           |
|       8 |    64 | Zeroes      | Protocol | UDP         | Length    |
|      12 |    96 | Source      | port     | Destination | Port      |
|      16 |   128 | Length      | (h+data) | Check       | sum       |
|      20 |  160+ | Data        |          |             |           |


#+BEGIN_SRC ditaa :file data-feed.png

+------------+
|            |
|  Radius    +------------+
|            |            |             +----------+   +-------+   +-------------+
+-------+----+            |             | Spark    |   |  .dat |   | Splunk      |
        |                 +---Redis---->+ Analytics+-->+       +-->+ Universal   |
        v                 |             | Daemon   |   |  file |   | Forwarder   |
+-------+------+          |             +----------+   +-------+   +-------------+
|              |          |
| Spark        +----------+
|  (sparkDB)   |
+-------+------+
        |
        v
+-------+--------+
|                |
|    Flint       |
|                |
+----------------+

#+END_SRC

#+RESULTS:
[[file:data-feed.png]]


#+BEGIN_SRC ditaa :file c:/Users/phewson/analytics.png

+--------------+            +------------------------+
| Splunk       +----------->+ (splunk                |     +---------------+
| Universal    |            |  Indexer 1)   Splunk   |     | Output        |
| Forwarder    +----------->+ (splunk       Search   +---->+ e.g. Customer |
+--------------+            | Indexer 2)    Head     |     | Dashboards    |
                            + -----------------------+     +---------------+

#+END_SRC


#+END_SRC
#+BEGIN_SRC ditaa :file c:/Users/phewson/authentication.png

       +-----------------------------------------------+
       |                                               |
       v                   +------------------+        |
+------+--------+          | Web Admin        |        |
| (sparkDB)     +          | Client admin user|        |    +--------+--------+
+------+--------+          | *analytics role  |        |    | CWA Admin       |
       ^                   | *OAuth creds     |        |    +--------+--------+
       |                   +--+---------------+        |             |
       |                      |                        |             |
       +----------------------+                        |             |
       |                                               |             v
       v                                            +--+-------------+--+
+------+-------+                                    | CWA Analytics     |
| Splunk       |                                    +--+----------------+
| Search       |                                       |
| Head         +<--------------------------------------+
+--------------+

#+END_SRC


sourcetype=spark_data "PortalView" | fields hotspot.internet_address | stats count by hotspot.internet_address
sourcetype=spark_data "PortalView" | fields subscriber.zip_code | stats count by subscriber.zip_code

sourcetype=spark_data (view="PortalView") |  fields subscriber.zip_code | lookup ukpostcodes.csv postcode AS subscriber.zip_code | geostats count by subscriber.zip_code latfield=latitude longfield=longitude

sourcetype=spark_data (view="PortalView") |  fields subscriber.zip_code | lookup OAC_by_postcode.csv PCDS AS subscriber.zip_code | stats count by SUBGRP

sourcetype=spark_data (view="PortalView") |  fields subscriber.zip_code | lookup OAC_by_postcode.csv PCDS AS subscriber.zip_code output SUBGRP | lookup OAC_2011_description.csv SUBGRP output SUBGRP, supergroup, description | lookup interim_OAC_2011_names.csv SUBGRP | stats count by group_labels, description, f1, f2, f3 | sort count desc


sourcetype=spark_data (view="PortalView") |  fields subscriber.zip_code | lookup OAC_by_postcode.csv PCDS AS subscriber.zip_code output SUBGRP | lookup OAC_2011_description.csv SUBGRP |  lookup interim_OAC_2011_names.csv SUBGRP | stats count by subgroup_label, description, f1, f2, f3, f4  | sort count desc



* Regexp

 - Emacs replace tab is literally press the tab key and return
 - Emacs *replace-regexp* ^.\{6\} with \&,



* Dataflowchart

sourcetype=spark_data

af_ versus cf_

realm
login_type=[data_click, email_val, free_sub, free_subscriber]
reason=[expired, user_reset]
user_agent

annual_total_upload_data_gb	annual_total_download_data_gb

#+BEGIN_SRC dot :file data_f.png :cmdline -Kdot -Tpng
digraph G {
    compound=true;
    subgraph cluster0 {
    graph [fontname = "Calibri:style=Regular"];
    node [fontname = "Calibri:style=Regular"];
    edge [fontname = "Calibri:style=Regular"];
    label="Data Sources";
    color="purple";
    host [shape=record, label="{host:|{cloud |testing_core| testing_portal}|sourcetype='spark_data'}"];
    }

    subgraph cluster1 {
    graph [fontname = "Calibri:style=Regular"];
    node [fontname = "Calibri:style=Regular"];
    edge [fontname = "Calibri:style=Regular"];
    label="Event Data"
    key [shape=record, label="UID: | unique_session_id"];
    type [shape=record, label="{type:|{<f1>Portal (Registration) |<f2> Stop/Start (Session)}}"];
    start [shape=record, label="{Start|{termination_clause:}|{null | Resumed}}", color=blue];
    edge [color="red"];
    type:f1 -> portal;
    edge [color="blue"];
    type:f2 -> stop;
    edge [color="blue"];
    type:f2 -> start;
    portal [shape=record,
            label="{view|{PortalView_Login_FreeSub | PortalView_NotHotspot | PortalView_Process_FreeSub}|
            {<p1>EmailValidation | <p2>NewUser | <p3>PortalView | <p4>PortalView_Login | <p5>ResetUser}}", color=red];
    stop [shape=record, label="{Stop|{termination_clause:}|
          {<t0>User-Request | <t1>Suspect-Logout | <t2>Resumed | <t3>Session-Timeout | <t4>Idle-Timeout |
           <t5>Idle-Timeout-Cron}}",
          color="red"];
    stop:t0 -> usage;
    stop:t2 -> usage;
    stop:t3 -> usage;
    stop:t4 -> usage;
    stop:t5 -> usage;
    usage [shape=record, label="input octets/gigawords  | output octets/gigawords",
           color="blue"];
    spage [shape=record, label="{page|{account_login | manage_account |a ccount_registration |welcome_back}|
           {validation_required | wifi_registration | account_success | form_data}}",color=red];
    edge [color="red"];
    portal:p3 -> spage;
    customer_info [shape=record, label="{customer|{id | name | zone_id | zone_name}}"];
    hotspot [shape=record, label="{hotspot | {latitude | longitude | location | id  | internet_address} |
             {type | zone_id | zone_name | mac | symbol | name | timezone}}"];
    hotspot_id [shape=record, label="hotspot_id"];
    customer_id [shape=record, label="customer_id"];
    }
    host -> type [ltail=cluster0,lhead=cluster1];
    usage -> customer_id;
    customer_id -> hotspot_id;
    start -> customer_id;
    spage -> customer_info;
    customer_info -> hotspot;

}
#+END_SRC

#+RESULTS:
[[file:data_f.png]]

#+BEGIN_SRC dot :file splunk_dev_infra.png :cmdline -Kdot -Tpng
digraph G {

  subgraph cluster_location {
    graph [fontname = "Calibri:style=Regular"];
    node [fontname = "Calibri:style=Regular"];
    label="";
    style="filled";
    color="gray61";
    fillcolor="gray61";
    location [shape=record, fillcolor="gold2", style="filled", label="{Location Data|{Ruckus|Meraki}}"];
  };

  subgraph cluster_portals {
    graph [fontname = "Calibri:style=Regular"];
    node [fontname = "Calibri:style=Regular"];
    label="";
    style="filled";
    color="gray61";
    fillcolor="gray61";
    portals [shape=record, fillcolor="gold2", style="filled", label="{{Redirect Portals|Portal Generator}}"];
  };

  subgraph cluster_redis {
    graph [fontname = "Calibri:style=Regular"];
    node [fontname = "Calibri:style=Regular"];
    label="";
    style="filled";
    color="gray61";
    fillcolor="gray61";
    redis [shape=record, fillcolor="gold2", style="filled", label="{{<F0>API|<F1>Radius}|{<F2>Redis}}"];
  };

  subgraph cluster_dat {
    graph [fontname = "Calibri:style=Regular"];
    node [fontname = "Calibri:style=Regular"];
    label="";
    style="filled";
    color="gray61";
    fillcolor="gray61";
    dat_file [shape=record, fillcolor="gold2", style="filled", label="{Data daemon|{spark-phase11/src/master/spark-analytics-data/}|{Outputs .dat file}|{\<text date, ip, server\> INFO \{json\}}}"];
  };

  subgraph cluster_forwarder {
    graph [fontname = "Calibri:style=Regular"];
    node [fontname = "Calibri:style=Regular"];
    label = "";
    style="filled";
    color="gray61";
    fillcolor="gray61";
    forwarder [shape=record, fillcolor="gold2", style="filled", label="{Forwarder|{/opt/splunkforwarder/etc/apps/search/local/inputs.conf}}"];
  };

  subgraph cluster_conf {
    graph [fontname = "Calibri:style=Regular"];
    node [fontname = "Calibri:style=Regular"];
    label="";
    style="filled";
    color="lightseagreen";
    fillcolor="lightseagreen";
    cluster_confs [shape=record, fillcolor="gold2", style="filled", label="{Unknown (app)|{/opt/splunk/etc/apps/\<app\>/local/transforms.conf}|{/opt/splunk/etc/apps/\<app\>/local/props.conf}}"];
  };

  subgraph cluster_0indexer1 {
    graph [fontname = "Calibri:style=Regular"];
    node [fontname = "Calibri:style=Regular"];
    label="Split index by customer id";
    style="filled";
    color="lightseagreen";
    fillcolor="lightseagreen";
    indexer1 [shape=record, fillcolor="gold2", style="filled", label="{<F1> indexer|{<F2> wfs-development-splunk-indexer1}|{c4.large | 34.254.115.197}}"];
  };

  subgraph cluster_1indexer2 {
    graph [fontname = "Calibri:style=Regular"];
    node [fontname = "Calibri:style=Regular"];
    label="Split index by customer id";
    style="filled";
    color="lightseagreen";
    fillcolor="lightseagreen";
    indexer2 [shape=record, fillcolor="gold2", style="filled", label="{<F1> indexer |{<F2> wfs-development-splunk-indexer2}|{c4.large | 52.210.107.135}}"];
  };

  subgraph cluster_2search {
    graph [fontname = "Calibri:style=Regular"];
    node [fontname = "Calibri:style=Regular"];
    label="";
    style="filled";
    color="seagreen";
    fillcolor="seagreen";
    search [shape=record, fillcolor="gold2", style="filled", label="{<F1> search head |{<F2> wfs-development-splunk-search}|{c4.large | 52.48.117.173}}"];
  };

  subgraph cluster_search_conf {
    graph [fontname = "Calibri:style=Regular"];
    node [fontname = "Calibri:style=Regular"];
    label="";
    style="filled";
    color="seagreen";
    fillcolor="seagreen";
    search_confs [shape=record, fillcolor="gold2", style="filled", label="{All_Field_Aliases (app) |{/opt/splunk/etc/apps/all_field_aliases/local/transforms.conf} |{/opt/splunk/etc/apps/all_field_aliases/local/props.conf}}"];
  };


  indexer1 -> search [penwidth=3.0];
  indexer2 -> search [penwidth=3.0];
  dat_file -> forwarder [penwidth=3.0];
  forwarder -> indexer1 [penwidth=3.0];
  forwarder -> indexer2 [penwidth=3.0];
  search_confs -> search:F2 [arrowhead="dot"];
  cluster_confs -> indexer1:F2 [arrowhead="dot"];
  cluster_confs -> indexer2:F2 [arrowhead="dot"];
  portals -> redis:F1 [penwidth=3.0];
  redis:F2 -> dat_file [penwidth=3.0];

}
#+END_SRC

#+RESULTS:
[[file:splunk_dev_infra.png]]

#+BEGIN_SRC dot :file splunk_dev.png :cmdline -Kdot -Tpng
digraph G {
  bgcolor="gray61";
  /* admin;
  poweruser;
  user;
  admin -> poweruser -> user; */

  subgraph cluster_source {
    graph [fontname = "Calibri:style=Regular"];
    node [fontname = "Calibri:style=Regular"];
    label="";
    style="filled";
    color="lightseagreen:seagreen";
    fillcolor="lightseagreen:seagreen";
    gradientangle=270;
    source_spark [shape=record, fillcolor="gold2", style="filled", label="{source|{/usr/local/spark/logs/spark-analytics-filter.dat}}"];
    source_location [shape=record, fillcolor="gold2", style="filled", label="{source|{/usr/share/location-data-collection/output/cloud_spark_location_NUMBER.dat}}"];
}
  subgraph cluster_host {
    graph [fontname = "Calibri:style=Regular"];
    node [fontname = "Calibri:style=Regular"];
    label="";
    style="filled";
    color="lightseagreen";
    fillcolor="lightseagreen";
    host_location [shape=record, fillcolor="gold2", style="filled", label="{host|{ip-10-0-1-73 | location-test.wifispark.net}}"];
    host_spark [shape=record, fillcolor="gold2", style="filled", label="{host|{cloud | testing_core | testing_portal}}"];
}
  subgraph cluster_data {
    graph [fontname = "Calibri:style=Regular"];
    node [fontname = "Calibri:style=Regular"];
    label="";
    style="filled";
    color="seagreen";
    fillcolor="seagreen";
    source_types [shape=record, fillcolor="gold2", style="filled",
                  label="{source_types|{<ST1>spark_data}|{<ST2>location_data}|{egton_radius_data}|{westpoint_location_data}}"];
    indexes [shape=record, fillcolor="gold2", style="filled",
             label="{indexes|{<I1>cloud_spark_NUMBER}|{<I2>hotsplot_NUMBER}|{<I3>spark_analytics_data_monitoring}|{spark_data_feed_failures}|{spark_data_feed_monitoring}|{BESPOKE_CUSTOMERS}|{BESPOKE_TESTS/DEMOS}}"];
}
  source_spark -> source_types:ST1 [color="red"];
  source_location -> source_types:ST2;
  source_spark -> indexes:I1;
  source_location -> indexes:I2;
  host_spark -> source_spark;
  host_location -> source_location;
  indexes:I1 -> source_types:ST1;
  {rank=same indexes source_types}


}
#+END_SRC

#+RESULTS:
[[file:splunk_dev.png]]



#+BEGIN_SRC dot :file zendesk.png :cmdline -Kdot -Tpng
digraph G {
  bgcolor="gray61";

  subgraph cluster_zendesk {
    graph [fontname = "Calibri:style=Regular"];
    node [fontname = "Calibri:style=Regular"];
    label="";
    style="filled";
    color="lightseagreen:seagreen";
    fillcolor="lightseagreen:seagreen";
    gradientangle=270;
    zendesk [shape=record, fillcolor="gold2", style="filled", label="{Zendesk|{<c0>Config: List of 'sites'}}"];
}

  subgraph cluster_api {
    graph [fontname = "Calibri:style=Regular"];
    node [fontname = "Calibri:style=Regular"];
    label="";
    style="filled";
    color="lightseagreen:seagreen";
    fillcolor="lightseagreen:seagreen";
    gradientangle=270;
    api [shape=record, fillcolor="gold2", style="filled", label="{REST API |{api/v2/tickets.json}|{Rate Limited/Must Paginate}}"];
}

  subgraph cluster_daemon {
    graph [fontname = "Calibri:style=Regular"];
    node [fontname = "Calibri:style=Regular"];
    label="";
    style="filled";
    color="lightseagreen:seagreen";
    fillcolor="lightseagreen:seagreen";
    gradientangle=270;
    daemon [shape=record, fillcolor="gold2", style="filled", label="{Daemon|{To be determined}}"];
}

  subgraph cluster_datastore {
    graph [fontname = "Calibri:style=Regular"];
    node [fontname = "Calibri:style=Regular"];
    label="";
    style="filled";
    color="lightseagreen:seagreen";
    fillcolor="lightseagreen:seagreen";
    gradientangle=270;
    datastore [shape=record, fillcolor="gold2", style="filled", label="{Data store |{To be determined} |{Data need to be editable}}"];
}

  subgraph cluster_splunk {
    graph [fontname = "Calibri:style=Regular"];
    node [fontname = "Calibri:style=Regular"];
    label="";
    style="filled";
    color="lightseagreen:seagreen";
    fillcolor="lightseagreen:seagreen";
    gradientangle=270;
    splunk [shape=record, fillcolor="gold2", style="filled", label="{Splunk | {<c0>Data Presentation (Dashboard)}}"];
}

  subgraph cluster_splunk_ki {
    graph [fontname = "Calibri:style=Regular"];
    node [fontname = "Calibri:style=Regular"];
    label="";
    style="filled";
    color="lightseagreen:seagreen";
    fillcolor="lightseagreen:seagreen";
    gradientangle=270;
    splunk_ki [shape=record, fillcolor="gold2", style="filled", label="{Splunk Index | {Intelligent API reading????}|{Editable data???}}"];
}


zendesk -> api;
api -> daemon;
daemon -> datastore;
datastore -> splunk;
api -> splunk_ki;
splunk_ki -> splunk;
zendesk:c0 -> splunk:c0 [label="Site to customer" labeltooltip="lookup" arrowhead = diamond color = "red"];
}
#+END_SRC


#+RESULTS:
[[file:zendesk.png]]


Splunk assigns host values as follows:

1. Any event-specific host assignment that you specify in transforms.conf.
2. The default host value for the input that created the event, if any (the forwarder or indexer which first consumes the data)
3. The default host value for the Splunk indexer or forwarder that initially consumes the data.

Splunk indexes

We have one index per customer. The data for these are stored in distinct folders. This seems to be the place to control access.

Why do we need to restrict permissions by host, why not by index?
Why not use tagging cloud=blah blah blah
Tags could be different in prod/dev. They would be the only thing that different.

wmi-override-host


*** Spark Schema

#+BEGIN_SRC dot :file spark_schema.png :cmdline -Kdot -Tpng
digraph G {
  bgcolor="gray61";

  subgraph cluster_spark {
    graph [fontname = "Calibri:style=Regular"];
    node [fontname = "Calibri:style=Regular"];
    label="spark";
    style="filled";
    color="lightseagreen:seagreen";
    fillcolor="lightseagreen:seagreen";
    gradientangle=270;
    spark [shape=record, fillcolor="gold2", style="filled", label="{account_location_activation | {admin_rights}|{admin_roles}|{admin_users}|{allowed_port_assoc}|{allowed_ports}|{allowed_ports_groups}|{bandwidth_types}|{bandwidth_classes}|{bandwidth_type_class_assoc}|
      {black_addresses_assoc}|{black_firewall_assoc}|{black_listed_addresses}|{black_lists}|
{cc_clearing_houses}|{cc_transaction_statuses}|{cc_transactions}|{<currencies>currencies}|{cust_oper_modes}|
{contacts}|{gdpr}|{<customers>customers}|{firewall_types}|{firewalls}|{hotspot_alarms}|{hotspot_alarm_details}|
{hotspot_alarm_statues}|{hotspot_interfaces}|{hotspot_lang_assoc}|{hotspot_statuses}|
{hotspot_tariff_classes}|{hotspot_types}|{<hotspots>hotspots}|{hotspot_macs}|{key_performance_indicator}|
{languages}|{mac_addresses}|{mac_login_types}|{mac_port_assoc}|{mac_provision}|{mac_provision_hotspot_assoc}|
{manual_transaction_charge_allocations}|{manual_transactions}|{pp_accounts}|{pp_transaction_statuses}|
{pp_transactions}|{role_right_assoc}|{room_charges}|{room_charges_transaction_statuses}|
{spark_statistics}|{subscriber_additional_fields}|{subscriber_block_statuses}|{subscriber_types}|
{<subscribers>subscribers}|{subscribers_accounts}|{synchronization_tasks}|{tariff_class_items}|
{voucher_reconciliation_types}|{voucher_statuses}|{voucher_tariff_charge_ranges}|
{voucher_tariffs}|{voucher_types}|{vouchers}|{walled_garden_addresses}|
{walled_gardens}|{walled_hotspot_assoc}|{walled_interface_assoc}|{templates}|
{zones}|{vat_classes}|{vat_rates}|{time_provisions}|{mac_provisioning_in_radius}|
{subscriber_account_mac_assoc}|{partial_refund}|{customer_subscriber_access}|{api_request_counter}|
{vat_rate_dates}|{<f1>free_subs}|{<social_media_login>social_media_login}}"];

    }

/*  subgraph cluster_radius {
    graph [fontname = "Calibri:style=Regular"];
    node [fontname = "Calibri:style=Regular"];
    label="radius";
    style="filled";
    color="lightseagreen:seagreen";
    fillcolor="lightseagreen:seagreen";
    gradientangle=270;
    radius [shape=record, fillcolor="gold2", style="filled", label="{<r0>radacct|{radcheck}|{radgroupcheck}|
{radgroupreply}|{radreply}|{radusergroup}|{radpostauth}|{callingstationidauth}}"];
    } */

  subgraph cluster_radius_history {
    graph [fontname = "Calibri:style=Regular"];
    node [fontname = "Calibri:style=Regular"];
    label="radius / radius history";
    style="filled";
    color="lightseagreen:seagreen";
    fillcolor="lightseagreen:seagreen";
    gradientangle=270;
    radius_history [shape=record, fillcolor="gold2", style="filled", label="{<r0>radacct|{radcheck}|{radgroupcheck}|
{radgroupreply}|{radreply}|{radusergroup}|{radpostauth}|{callingstationidauth}}"];
    }

  subgraph cluster_reporting {
    graph [fontname = "Calibri:style=Regular"];
    node [fontname = "Calibri:style=Regular"];
    label="reporting";
    style="filled";
    color="lightseagreen:seagreen";
    fillcolor="lightseagreen:seagreen";
    gradientangle=270;
    reporting [shape=record, fillcolor="gold2", style="filled", label="{<r0>free_use_data_extract|{r.acctstarttime |fs1.first_name | fs1.last_name |
fs1.email | fs1.zip_code | fs1.mac_address | r1.nasportid count}}"];
    }

  subgraph cluster_report_tool {
    graph [fontname = "Calibri:style=Regular"];
    node [fontname = "Calibri:style=Regular"];
    label="report_tool";
    style="filled";
    color="lightseagreen:seagreen";
    fillcolor="lightseagreen:seagreen";
    gradientangle=270;
    report_tool [shape=record, fillcolor="gold2", style="filled", label="{
<v0>report_definition|{<v1>report_filter}|
{<report_aggregation>report_aggregation}|{report_aggregation_aggregate_column}|{report_aggregation_group_column}|
{frequency_type}|{<rv>report_version}|{report_version_filter}|{report_version_aggregation}|
{report_version_aggregation}|{report_version_excluded_column}|{report_version_column_sorting}|
{<rs>report_schedule}|{report_schedule_filter}|{report_password}|{report_password_history}|
{report_requester}|{report_requester_assoc}|{report_schedule_sent}|{report_execution_result}|
{report_execution_result_filter}|{webadmin_request}|{report_requester_customer_view}|
{report_sessions}|{helper_zone_hotspot_assoc}|{free_subscribers_signups_view}|{report_free_subscriber_session}|
{helper_subscriber}|{helper_voucher}|{helper_mac_provisioning_in_radius}|{helper_all_users_except_free_sub}|
{<active_subs>active_subscribers_view}|{heavy_haulers_view}|{helper_subscriber_activation}|{recurring_manual_actuations_view}|
{refunds_view}|{<ssv>subscribers_sessions_view}|{all_transactions_helper}|{subscriber_latest_transaction}|
{<sw>subscribers_w_sessions_latest_transaction}|{distinct_hotspot_internet_addresses_view}|
{<completed_transactions_view>completed_transactions_view}|
{<revenue_view>revenue_view}|{<sessions_view>sessions_view}|{cc_accepted_transactions_view}|{<socialmedia_view>socialmedia_view}|
{<radius_accounting>radius_accounting}|
{<dsssv>daily_subscribers_signups_and_sessions_view}|{<tsbdv>total_sessions_by_day_view}}"];
}

subgraph cluster_php {
    graph [fontname = "Calibri:style=Regular"];
    node [fontname = "Calibri:style=Regular"];
    label="PHP Reporting script";
    style="filled";
    color="lightseagreen:seagreen";
    fillcolor="lightseagreen:seagreen";
    gradientangle=270;
    php [shape=record, fillcolor="gold2", style="filled", label = "{<php>report_scheduler|{<report_aggregation>report_aggregation}}"]
}

/*  subgraph cluster_report_tool_temp {
    graph [fontname = "Calibri:style=Regular"];
    node [fontname = "Calibri:style=Regular"];
    label="report_tool_temp";
    style="filled";
    color="lightseagreen:seagreen";
    fillcolor="lightseagreen:seagreen";
    gradientangle=270;
    report_tool_temp [shape=record, fillcolor="gold2", style="filled", label="{source|{/usr/local/spark/logs/spark-analytics-filter.dat}}"];
    } */

/*  subgraph cluster_backups {
    graph [fontname = "Calibri:style=Regular"];
    node [fontname = "Calibri:style=Regular"];
    label="backups";
    style="filled";
    color="lightseagreen:seagreen";
    fillcolor="lightseagreen:seagreen";
    gradientangle=270;
    backups [shape=record, fillcolor="gold2", style="filled", label="{source|{/usr/local/spark/logs/spark-analytics-filter.dat}}"];
    } */

/* radius -> radius_history[constraint=false]; */

radius_history:r0 -> reporting:r0;
spark:f1 -> reporting:r0
radius_history:r0 -> report_tool:tsbdv

radius_history:r0 -> report_tool:dsssv
spark:hotspots -> report_tool:dsssv
spark:subscribers -> report_tool:dsssv

radius_history:r0 -> report_tool:radius_accounting
spark:hotspots -> report_tool:radius_accounting

spark:hotspots -> report_tool:socialmedia_view
radius_history:r0 -> report_tool:socialmedia_view
spark:social_media_login -> report_tool:socialmedia_view

report_tool:completed_transactions_view -> report_tool:revenue_view;
spark:hotspots -> report_tool:revenue_view
spark:customers -> report_tool:revenue_view
spark:spark_currencies -> report_tool:revenue_view

spark:hotspots -> report_tool:sw
spark:subscribers -> report_tool:sw
radius_history:r0 -> report_tool:sw

radius_history:r0 -> report_tool:ssv
spark:hotspots -> report_tool:ssv
spark:subscribers -> report_tool:ssv

radius_history:r0 -> report_tool:active_subs
spark:hotspots -> report_tool:active_subs

radius_history:r0 -> report_tool:sessions_view
spark:hotspots -> report_tool:sessions_view
spark:customers -> report_tool:sessions_view

report_tool:rs -> php:php
report_tool:rv -> php:php

report_tool:report_aggregation -> php:report_aggregation


}
#+END_SRC

#+RESULTS:
[[file:spark_schema.png]]


#+BEGIN_SRC dot :file spark_v_splunk.png :cmdline -Kdot -Tpng
digraph G {
  bgcolor="gray61";

  subgraph cluster_spark {
    graph [fontname = "Calibri:style=Regular"];
    node [fontname = "Calibri:style=Regular"];
    label="Spark";
    style="filled";
    color="lightseagreen:seagreen";
    fillcolor="lightseagreen:seagreen";
    gradientangle=270;
    spark_radius [shape=record, fillcolor="gold2", style="filled", label="{spark|{radius}|{radius_backup}}"];
    }

  subgraph cluster_splunk {
    graph [fontname = "Calibri:style=Regular"];
    node [fontname = "Calibri:style=Regular"];
    label="Splunk";
    style="filled";
    color="lightseagreen:seagreen";
    fillcolor="lightseagreen:seagreen";
    gradientangle=270;
    splunk [shape=record, fillcolor="gold2", style="filled", label="{redis|{data_daemon}|{splunk_forwarder}|{splunk_indexer}|{splunk_search}}"];
    }

  subgraph cluster_django {
    graph [fontname = "Calibri:style=Regular"];
    node [fontname = "Calibri:style=Regular"];
    label="Django Dashboard App";
    style="filled";
    color="lightseagreen:seagreen";
    fillcolor="lightseagreen:seagreen";
    gradientangle=270;
    django [shape=record, fillcolor="gold2", style="filled", label="{admin_db |{Spunk API calls}}"];
    }

  subgraph cluster_report {
    graph [fontname = "Calibri:style=Regular"];
    node [fontname = "Calibri:style=Regular"];
    label="Finance/Customer Service Reports";
    style="filled";
    color="lightseagreen:seagreen";
    fillcolor="lightseagreen:seagreen";
    gradientangle=270;
    report [shape=record, fillcolor="gold2", style="filled", label="{spark 11 dbs |{Report.php}}"];
    }

    subgraph customer {
    graph [fontname = "Calibri:style=Regular"];
    node [fontname = "Calibri:style=Regular"];
    label="Customer";
    style="filled";
    color="lightseagreen:seagreen";
    fillcolor="lightseagreen:seagreen";
    gradientangle=270;
    customer [shape=record, fillcolor="gold2", style="filled", label="{<f0>Received report |{<f1>Pulls dashboard query}}"];
    }


report -> customer:f0
spark_radius -> report;
spark_radius -> splunk;
splunk -> django;
django -> customer:f1

}

#+END_SRC

#+RESULTS:
[[file:spark_v_splunk.png]]
